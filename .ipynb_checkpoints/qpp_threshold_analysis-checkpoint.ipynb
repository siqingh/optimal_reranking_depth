{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27a75cf1-95d4-431a-9c3e-caa6056389fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.patches import Patch\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import numpy as np\n",
    "import statistics\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from utils import convert_run, dcg, dcg_from_run, dcg_for_query, load_umbrela_scores, make_equal_content_bins, assign_to_bin, prettify_label\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams[\"font.family\"] = \"Times New Roman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f576405f-6f8e-4dbd-b445-6b87f682f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"data/full_data.tsv\", sep=\"\\t\")\n",
    "data_df['max_vs_fully_reranked'] = data_df['max_dcg_value_mono_1000'] / data_df['mono_1000_reranked_all_dcg_value']\n",
    "optimal_depth_avg = data_df['max_dcg_value_mono_1000_depth'].mean()\n",
    "max_vs_fully_reranked_ratio_avg = data_df['max_vs_fully_reranked'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb30feb8-c63f-4704-beba-0b4ee867077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_content_prediction_ten_fold_validation(initial_metric_col, fully_reranked_col, retriever, metric, \n",
    "                                                 reranker, rerank_depth_array, no_plot=False):\n",
    "    main_df = data_df[[\"query_id\", initial_metric_col, fully_reranked_col, \n",
    "                  f\"max_{metric}_value_{reranker}\", f\"max_{metric}_value_{reranker}_depth\"]].copy()\n",
    "\n",
    "    metric_value_lookup_df = pd.read_csv(f\"data/all_queries_all_depth-{retriever}-{reranker}-{metric}.csv\")\n",
    "    metric_value_lookup_df_indexed = metric_value_lookup_df.set_index([\"query_id\", \"depth\"])\n",
    "\n",
    "    # Split all the data into 10 folds\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    folds = []\n",
    "    for train_idx, test_idx in kf.split(main_df):\n",
    "        train_df = main_df.iloc[train_idx]\n",
    "        test_df = main_df.iloc[test_idx]\n",
    "        folds.append((train_df, test_df))\n",
    "\n",
    "    percentiles = [90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n",
    "    data = []\n",
    "\n",
    "    for index, (train_df, test_df) in enumerate(folds):\n",
    "        train_df = train_df.copy()\n",
    "        test_df = test_df.copy()\n",
    "\n",
    "        # Use training data to get equal content bucket\n",
    "        bin_edges = make_equal_content_bins(train_df[initial_metric_col], n_bins=10)\n",
    "\n",
    "        # Assign all data to corresponding metric bins\n",
    "        train_df['metric_bin'] = train_df[initial_metric_col].apply(lambda x: assign_to_bin(x, bin_edges))\n",
    "        train_df['metric_bin'] = pd.Categorical(\n",
    "            train_df['metric_bin'],\n",
    "            ordered=True,\n",
    "            categories=sorted(set(train_df['metric_bin']), key=lambda x: float(x.split('~')[0]))\n",
    "        )\n",
    "        test_df['metric_bin'] = test_df[initial_metric_col].apply(lambda x: assign_to_bin(x, bin_edges))\n",
    "        test_df['metric_bin'] = pd.Categorical(\n",
    "            test_df['metric_bin'],\n",
    "            ordered=True,\n",
    "            categories=sorted(set(test_df['metric_bin']), key=lambda x: float(x.split('~')[0]))\n",
    "        )\n",
    "\n",
    "        # train data's initial metric value metric bin -> rerank depth that maximizes the metric\n",
    "        train_initial_metric_to_optimal_depths = (\n",
    "            train_df.groupby(\"metric_bin\", observed=True)[f\"max_{metric}_value_{reranker}_depth\"]\n",
    "              .apply(lambda x: sorted(x.tolist()))\n",
    "              .to_dict()\n",
    "        )\n",
    "\n",
    "        for p in percentiles:\n",
    "            # For each training data metric bin, get all optimal depths\n",
    "            for metric_bin, depths in train_initial_metric_to_optimal_depths.items():\n",
    "                # The pth percentile of the optimal depths is the predicted depth for test data in this metric bin\n",
    "                depth_p = int(np.percentile(depths, p))\n",
    "        \n",
    "                # get test queries in this bin\n",
    "                df_bin = test_df[test_df[\"metric_bin\"] == metric_bin]\n",
    "        \n",
    "                for _, row in df_bin.iterrows():\n",
    "                    if metric == \"dcg\":\n",
    "                        metric_at_depth_p = metric_value_lookup_df_indexed.loc[(row['query_id'], depth_p), \"metric_value_at_depth\"]\n",
    "\n",
    "                    data.append([index, p, row['query_id'], depth_p, \n",
    "                                 row[fully_reranked_col], \n",
    "                                 row[initial_metric_col], \n",
    "                                 row[f\"max_{metric}_value_{reranker}\"],\n",
    "                                 row[f\"max_{metric}_value_{reranker}_depth\"],\n",
    "                                 metric_bin,\n",
    "                                 metric_at_depth_p, \n",
    "                                 0 if row[fully_reranked_col] == 0 else metric_at_depth_p / row[fully_reranked_col],\n",
    "                                 0 if row[f\"max_{metric}_value_{reranker}\"] == 0 else metric_at_depth_p / row[f\"max_{metric}_value_{reranker}\"],\n",
    "                                ])\n",
    "        \n",
    "    df = pd.DataFrame(data, columns=['Fold #', 'Percentile', 'Query ID', 'Predicted Depth', 'Reranked All Metric Value', \n",
    "                                     'Initial Metric Value', 'Maximum Metric Value', 'Depth of Maximum Metric Value',\n",
    "                                     'Bin',\n",
    "                                     'Metric Value At Predicted Depth', 'Ratio (Metric at Depth / Reranked All)',\n",
    "                                     'Ratio (Metric at Depth / Maximum Metric Value)'])\n",
    "\n",
    "    df.to_csv(f'data/equal_content_10_fold-{retriever}-{reranker}-{metric}-{initial_metric_col}.csv', index=False)\n",
    "\n",
    "    # Rerank all to the same depth\n",
    "    all_same_depth_avg_predicted_vs_fully_reranked_ratio = {}\n",
    "    all_same_depth_avg_predicted_vs_max_ratio = {}\n",
    "\n",
    "    for d in rerank_depth_array:\n",
    "        # get metrics at depth d\n",
    "        depth_df = metric_value_lookup_df_indexed.xs(d, level=\"depth\")[\n",
    "            [\"metric_value_at_depth\"]\n",
    "        ].reset_index()\n",
    "        \n",
    "        merged = depth_df.merge(main_df, on=\"query_id\", how=\"inner\")\n",
    "        merged[\"predicted_vs_fully_reranked\"] = (\n",
    "            merged[\"metric_value_at_depth\"] / merged[fully_reranked_col]\n",
    "        )\n",
    "        merged[\"predicted_vs_max\"] = (\n",
    "            merged[\"metric_value_at_depth\"] / merged[f\"max_{metric}_value_{reranker}\"]\n",
    "        )\n",
    "        all_same_depth_avg_predicted_vs_fully_reranked_ratio[d] = merged[\"predicted_vs_fully_reranked\"].mean()\n",
    "        all_same_depth_avg_predicted_vs_max_ratio[d]   = merged[\"predicted_vs_max\"].mean()\n",
    "\n",
    "    # Group data by percentile\n",
    "    grouped_ratio = df.groupby(\"Percentile\").agg(\n",
    "        avg_predicted_depth=(\"Predicted Depth\", \"mean\"),\n",
    "        avg_predicted_vs_fully_reranked_ratio=(\"Ratio (Metric at Depth / Reranked All)\", \"mean\"),\n",
    "        avg_predicted_vs_max_ratio=(\"Ratio (Metric at Depth / Maximum Metric Value)\", \"mean\")\n",
    "    ).reset_index()\n",
    "    grouped_ratio = grouped_ratio.sort_values(\"avg_predicted_depth\")\n",
    "\n",
    "    return all_same_depth_avg_predicted_vs_fully_reranked_ratio, grouped_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde5e271-9f56-48ac-820c-e35ec8ddd1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pyterrier/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:4653: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/opt/anaconda3/envs/pyterrier/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:4653: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/opt/anaconda3/envs/pyterrier/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:4653: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/opt/anaconda3/envs/pyterrier/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:4653: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/opt/anaconda3/envs/pyterrier/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:4653: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/opt/anaconda3/envs/pyterrier/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:4653: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/opt/anaconda3/envs/pyterrier/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:4653: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/opt/anaconda3/envs/pyterrier/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:4653: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/opt/anaconda3/envs/pyterrier/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:4653: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    }
   ],
   "source": [
    "# Obtain all QPP's data\n",
    "reranker = \"mono_1000\"\n",
    "metric = \"dcg\"\n",
    "qpp_metrics = ['NQC', 'UEF', 'RSD', 'OddsRatio', 'WIG', 'Scaled NQC', 'QV-NQC Variant', 'DenseQPP', 'SMV', 'Sigma_max', 'Sigma_x']\n",
    "qpp_rows = []\n",
    "\n",
    "for qpp_metric in qpp_metrics:\n",
    "    _, grouped_ratio = equal_content_prediction_ten_fold_validation(\n",
    "        qpp_metric, \"mono_1000_reranked_all_dcg_value\", \"bm25\", \"dcg\", \"mono_1000\", [0, 1, 2, 5, 10, 20, 30, 50, 100, 250, 500, 800, 1000],\n",
    "        True)\n",
    "\n",
    "    mask = grouped_ratio[\"avg_predicted_vs_fully_reranked_ratio\"] >= 1\n",
    "    if mask.any(): # Get the smallest threshold such that ratio >= 1\n",
    "        result_row = grouped_ratio.loc[mask].sort_values(\"Percentile\").iloc[0]\n",
    "    else: # Return the threshold that yields the maximum ratio if it never reaches 1\n",
    "        result_row = grouped_ratio.loc[\n",
    "            grouped_ratio[\"avg_predicted_vs_fully_reranked_ratio\"].idxmax()\n",
    "        ]\n",
    "\n",
    "    qpp_rows.append({\n",
    "        \"QPP Measure\": qpp_metric,\n",
    "        \"Threshold\": result_row['Percentile'] / 100,\n",
    "        \"Average DCG@10 Ratio\": result_row[\"avg_predicted_vs_fully_reranked_ratio\"],\n",
    "        \"Average Predicted Depths\": result_row[\"avg_predicted_depth\"],\n",
    "    })\n",
    "\n",
    "qpp_df = pd.DataFrame(qpp_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09ec8127-775f-4054-8d9b-3d8df1c56395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "QPP Measure & Average Predicted Depths & Average DCG@10 Ratio & Threshold \\\\\n",
      "\\midrule\n",
      "NQC & 846.439 & 1.000 & 0.980 \\\\\n",
      "UEF & 736.390 & 1.000 & 0.960 \\\\\n",
      "RSD & 533.900 & 1.000 & 0.900 \\\\\n",
      "OddsRatio & 923.637 & 1.000 & 1.000 \\\\\n",
      "WIG & 961.294 & 0.999 & 1.000 \\\\\n",
      "Scaled NQC & 846.439 & 1.000 & 0.980 \\\\\n",
      "QV-NQC Variant & 846.439 & 1.000 & 0.980 \\\\\n",
      "DenseQPP & 992.380 & 0.999 & 1.000 \\\\\n",
      "SMV & 764.217 & 1.001 & 0.970 \\\\\n",
      "Sigma_max & 894.311 & 0.999 & 0.990 \\\\\n",
      "Sigma_x & 834.596 & 0.999 & 0.980 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(qpp_df.to_latex(index=False, float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2c55ff-d02d-4897-b904-43e34a124d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyterrier",
   "language": "python",
   "name": "pyterrier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
